#!/bin/bash
source $CSD181/hadoop/hadoop_shared/hadoop_bashrc.sh
shopt -s expand_aliases

# Option -t: use test sequencefiles (small)
# Option -r: recompile sequencefiles
# Option -c: copy reducer outputs to local and convert to MATLAB format

################################################################################

DIR_LOCAL=$MY_STOR/data/RSVP
DIR_HDFS=/user/$USER/RSVP
START_IDX=44
END_IDX=60
FILESTR=$MY_STOR/data/RSVP/exp?/realtime/exp?_continuous_with_ica

################################################################################

while getopts trc option
do
        case "${option}"
        in
                t) TEST=1;;
                r) RECOMPILE=1;;
                c) COPYTOLOCAL=1;;
        esac
done

#Create main IO directories
hdfs_input=$DIR_HDFS/hadoop_input
hdfs_output=$DIR_HDFS/hadoop_output
local_input=$DIR_LOCAL/hadoop_input
local_output=$DIR_LOCAL/hadoop_output

hdfs -rmr $hdfs_output > /dev/null 2>&1
hdfs -mkdir $hdfs_input > /dev/null 2>&1

if [ ! -d $local_output ]; then
	mkdir $local_output
fi

if [ ! -d $local_input ]; then
	mkdir $local_input
fi

#Using a small test dataset generated by eeglab2hadoop.py
if [ ! -z $TEST ]; then
    echo using test dataset

    hdfs_input=$DIR_HDFS/hadoop_input/test
    hdfs_output=$DIR_HDFS/hadoop_output/test
    local_input=$DIR_LOCAL/hadoop_input/test
    local_output=$DIR_LOCAL/hadoop_output/test

    if [ ! -d $local_input ]; then
	   mkdir $local_input
    fi

    if [ ! -d $local_output ]; then
	   mkdir $local_output
    fi

    hdfs -rmr $hdfs_output > /dev/null 2>&1
    hdfs -mkdir $hdfs_input> /dev/null 2>&1

#Use full sequencefiles
else
    echo using full dataset

    hdfs_input=$DIR_HDFS/hadoop_input/full
    hdfs_output=$DIR_HDFS/hadoop_output/full
    local_input=$DIR_LOCAL/hadoop_input/full
    local_output=$DIR_LOCAL/hadoop_output/full

    if [ ! -d $local_input ]; then
	   mkdir $local_input
    fi

    if [ ! -d $local_output ]; then
	   mkdir $local_output
    fi

    hdfs -rmr $hdfs_output > /dev/null 2>&1
    hdfs -mkdir $hdfs_input> /dev/null 2>&1
fi

#Convert EEGLAB files to sequencefiles
if [ ! -z $RECOMPILE ]; then
    echo recompiling local files, putting to HDFS:$hdfs_input

    echo deleting files in Local:$local_input
    rm -r $local_input/*

    if [ ! -z $TEST ]; then
        echo recompiling test sequencefiles
        eeglab2hadoop.py $FILESTR $START_IDX $END_IDX $local_input --testfile

    else
        echo recompiling full sequencefiles
        eeglab2hadoop.py $FILESTR $START_IDX $END_IDX $local_input --sequencefile
    fi

    echo deleting files in HDFS:$hdfs_input
    hdfs -rmr $hdfs_input/*

    echo copying from Local:$local_input to HDFS:$hdfs_input
    hdfs -copyFromLocal $local_input/* $hdfs_input
fi

#Determine number of map and reduce tasks (max 500 maps)
num=$(hdfs -ls $hdfs_input/|wc -l)
num_seq_files=$(expr $num - 1)

if [ ! -z $TEST ]; then
    num_chans=$(expr $num_seq_files \* 8)
else
    num_chans=$(expr $num_seq_files \* 256)
fi

if [ $(expr $(($num_chans>4000))) -eq 1 ]; then
    num_map_tasks=1000
else
    num_map_tasks=$(expr $num_chans \/ 4)
fi

echo "number of map tasks = $num_map_tasks"

################################################################################
#Submit job: configure hadoop paramters

had jar /opt/hadoop/contrib/streaming/hadoop-*streaming*.jar \
-input $hdfs_input/* \
-output $hdfs_output \
-file $MAPR/with_hdfs/mapper.py \
-file $MAPR/with_hdfs/process.py \
-file $MAPR/with_hdfs/reducer.py \
-mapper mapper.py \
-reducer reducer.py \
-inputformat SequenceFileAsTextInputFormat \
-jobconf mapred.map.tasks=$num_map_tasks \
-jobconf mapred.reduce.tasks=$num_seq_files \
-jobconf mapred.tasktracker.map.tasks.maximum=$num_map_tasks \
-jobconf mapred.tasktracker.reduce.tasks.maximum=$num_seq_files \
-jobconf mapred.max.tracker.failures=num_map_tasks \
-jobconf mapred.map.child.java.opts=-Xmx2048M \
-jobconf mapred.reduce.child.java.opts=-Xmx1024M \
-jobconf io.sort.mb=1024 \
-jobconf mapred.task.timeout=2000000 \
-jobconf mapred.map.max.attempts=10 \
-jobconf mapred.reduce.max.attempts=10 \
-jobconf mapred.skip.map.max.skip.records=1 \
-jobconf mapred.skip.attempts.to.start.skipping=4 \
-jobconf mapred.skip.mode.enabled=true \

################################################################################
#Copy from HDFS to local, convert to MATLAB format

if [ ! -z $COPYTOLOCAL ]; then
    subnumber=$(expr $(ls $local_output -p | grep "/"|wc -l) + 1)
    dirname=$local_output/out$subnumber

    echo copying results to $dirname
    mkdir $dirname
    hdfs -copyToLocal $hdfs_output/* $dirname

    echo converting to MATLAB format
    eeglab2hadoop.py $dirname 0 0 0 --hadoop2mat
fi

echo submit_job.sh: done